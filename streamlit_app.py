import streamlit as st
import asyncio
import time
from typing import Dict, Any
import json

# å¯¼å…¥æ·±åº¦ç ”ç©¶æ¨¡å—å’Œå¼‚æ­¥è¿è¡Œå™¨
from streamlit_runner import (
    run_research_workflow,
    create_research_config,
    format_research_result,
    async_runner,
    GRAPH_AVAILABLE,
)

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="ğŸ”¬ Deep Research Assistant",
    page_icon="ğŸ”¬",
    layout="wide",
    initial_sidebar_state="expanded",
)

# è‡ªå®šä¹‰CSS
st.markdown(
    """
<style>
    .main-header {
        font-size: 3rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .status-box {
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 1rem 0;
    }
    .status-running {
        background-color: #fff3cd;
        border: 1px solid #ffeaa7;
    }
    .status-complete {
        background-color: #d4edda;
        border: 1px solid #c3e6cb;
    }
    .status-error {
        background-color: #f8d7da;
        border: 1px solid #f5c6cb;
    }
</style>
""",
    unsafe_allow_html=True,
)

# ä¸»æ ‡é¢˜
st.markdown(
    '<h1 class="main-header">ğŸ”¬ Deep Research Assistant</h1>', unsafe_allow_html=True
)
st.markdown("---")

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if "messages" not in st.session_state:
    st.session_state.messages = []
if "research_history" not in st.session_state:
    st.session_state.research_history = []
if "current_status" not in st.session_state:
    st.session_state.current_status = "ç­‰å¾…è¾“å…¥"

# ä¾§è¾¹æ é…ç½®
with st.sidebar:
    st.header("âš™ï¸ é…ç½®é€‰é¡¹")

    # ç ”ç©¶é…ç½®
    st.subheader("ğŸ”§ ç ”ç©¶å‚æ•°")
    max_sections = st.slider("æœ€å¤§ç« èŠ‚æ•°", min_value=3, max_value=10, value=5)
    search_depth = st.slider("æœç´¢æ·±åº¦", min_value=1, max_value=5, value=2)

    # æ¨¡å‹é…ç½®
    st.subheader("ğŸ¤– æ¨¡å‹é…ç½®")
    writer_model = st.selectbox(
        "å†™ä½œæ¨¡å‹",
        ["gpt-4", "gpt-3.5-turbo", "claude-3-sonnet", "claude-3-haiku"],
        index=0,
    )

    planner_model = st.selectbox(
        "è§„åˆ’æ¨¡å‹", ["gpt-4", "claude-3-sonnet", "claude-3-haiku"], index=1
    )

    # æ˜¾ç¤ºå½“å‰çŠ¶æ€
    st.subheader("ğŸ“Š å½“å‰çŠ¶æ€")
    status_container = st.container()
    with status_container:
        if st.session_state.current_status == "ç­‰å¾…è¾“å…¥":
            st.markdown(
                '<div class="status-box">ğŸŸ¡ ç­‰å¾…ç ”ç©¶ä¸»é¢˜è¾“å…¥</div>',
                unsafe_allow_html=True,
            )
        elif "è¿›è¡Œä¸­" in st.session_state.current_status:
            st.markdown(
                f'<div class="status-box status-running">ğŸ”„ {st.session_state.current_status}</div>',
                unsafe_allow_html=True,
            )
        elif "å®Œæˆ" in st.session_state.current_status:
            st.markdown(
                f'<div class="status-box status-complete">âœ… {st.session_state.current_status}</div>',
                unsafe_allow_html=True,
            )
        else:
            st.markdown(
                f'<div class="status-box status-error">âŒ {st.session_state.current_status}</div>',
                unsafe_allow_html=True,
            )

    # ç ”ç©¶å†å²
    st.subheader("ğŸ“š ç ”ç©¶å†å²")
    if st.session_state.research_history:
        for i, topic in enumerate(st.session_state.research_history[-5:], 1):
            st.write(f"{i}. {topic[:30]}...")
    else:
        st.write("æš‚æ— ç ”ç©¶å†å²")

    # æ¸…é™¤å†å²æŒ‰é’®
    if st.button("ğŸ—‘ï¸ æ¸…é™¤å†å²", type="secondary"):
        st.session_state.messages = []
        st.session_state.research_history = []
        st.rerun()

# ä¸»ç•Œé¢å¸ƒå±€
col1, col2 = st.columns([2, 1])

with col1:
    st.subheader("ğŸ’¬ ç ”ç©¶å¯¹è¯")

    # èŠå¤©å®¹å™¨
    chat_container = st.container()

    with chat_container:
        # æ˜¾ç¤ºèŠå¤©å†å²
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                if message["role"] == "assistant":
                    # æ ¼å¼åŒ–åŠ©æ‰‹å›å¤
                    st.markdown(message["content"])
                    if "metadata" in message:
                        with st.expander("ğŸ“‹ è¯¦ç»†ä¿¡æ¯"):
                            st.json(message["metadata"])
                else:
                    st.markdown(message["content"])

with col2:
    st.subheader("ğŸ“ˆ ç ”ç©¶è¿›åº¦")
    progress_container = st.container()

    # å·¥ä½œæµå¯è§†åŒ–å ä½ç¬¦
    workflow_placeholder = st.empty()

# è¾“å…¥åŒºåŸŸ
st.markdown("---")
input_container = st.container()

with input_container:
    col_input, col_button = st.columns([4, 1])

    with col_input:
        user_input = st.text_input(
            "è¯·è¾“å…¥æ‚¨è¦ç ”ç©¶çš„ä¸»é¢˜:",
            placeholder="ä¾‹å¦‚: Web3çš„å‘å±•è¶‹åŠ¿å’ŒæŒ‘æˆ˜",
            key="topic_input",
            label_visibility="collapsed",
        )

    with col_button:
        submit_button = st.button(
            "ğŸš€ å¼€å§‹ç ”ç©¶", type="primary", use_container_width=True
        )


# å¤„ç†ç”¨æˆ·è¾“å…¥
def handle_research_request(
    topic: str, writer_model: str, planner_model: str, search_depth: int
):
    """å¤„ç†ç ”ç©¶è¯·æ±‚"""
    # åˆ›å»ºé…ç½®
    config = create_research_config(writer_model, planner_model, search_depth)

    # è¿è¡Œå¼‚æ­¥å·¥ä½œæµ
    future = async_runner.run_async_in_thread(run_research_workflow(topic, config))

    return future


def update_progress(step: str, progress: float):
    """æ›´æ–°è¿›åº¦æ˜¾ç¤º"""
    with progress_container:
        st.progress(progress)
        st.write(f"ğŸ”„ {step}")


# å½“ç”¨æˆ·æäº¤æ—¶
if submit_button and user_input:
    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
    st.session_state.messages.append({"role": "user", "content": user_input})
    st.session_state.research_history.append(user_input)

    # æ›´æ–°çŠ¶æ€
    st.session_state.current_status = "ç ”ç©¶è¿›è¡Œä¸­..."

    # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
    with chat_container:
        with st.chat_message("user"):
            st.markdown(user_input)

    # æ˜¾ç¤ºåŠ©æ‰‹æ€è€ƒè¿‡ç¨‹
    with chat_container:
        with st.chat_message("assistant"):
            thinking_placeholder = st.empty()
            thinking_placeholder.markdown("ğŸ¤” æ­£åœ¨åˆ†ææ‚¨çš„ç ”ç©¶ä¸»é¢˜...")

            # è¿›åº¦æ¡
            progress_bar = st.progress(0)
            status_text = st.empty()

            try:
                # æ¨¡æ‹Ÿè¿›åº¦æ›´æ–°
                steps = [
                    ("åˆ†æç ”ç©¶ä¸»é¢˜", 0.1),
                    ("ç”Ÿæˆç ”ç©¶è®¡åˆ’", 0.2),
                    ("æœç´¢ç›¸å…³ä¿¡æ¯", 0.4),
                    ("æ’°å†™ç ”ç©¶ç« èŠ‚", 0.7),
                    ("æ•´åˆæœ€ç»ˆæŠ¥å‘Š", 0.9),
                    ("å®Œæˆç ”ç©¶", 1.0),
                ]

                for step, progress in steps:
                    status_text.markdown(f"ğŸ”„ {step}...")
                    progress_bar.progress(progress)
                    time.sleep(1)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´

                    # å®é™…è¿è¡Œç ”ç©¶
                thinking_placeholder.markdown("âœ¨ æ­£åœ¨å¯åŠ¨æ·±åº¦ç ”ç©¶å·¥ä½œæµ...")

                # è¿è¡ŒçœŸå®çš„ç ”ç©¶å·¥ä½œæµ
                if GRAPH_AVAILABLE:
                    future = handle_research_request(
                        user_input, writer_model, planner_model, search_depth
                    )

                    # ç­‰å¾…ç»“æœï¼ˆæ¨¡æ‹Ÿè½®è¯¢ï¼‰
                    max_wait_time = 300  # æœ€å¤§ç­‰å¾…5åˆ†é’Ÿ
                    start_time = time.time()

                    while (
                        not future.done() and (time.time() - start_time) < max_wait_time
                    ):
                        elapsed = time.time() - start_time
                        progress = min(0.9, elapsed / 60)  # åŸºäºæ—¶é—´çš„è¿›åº¦ä¼°ç®—
                        progress_bar.progress(progress)
                        status_text.markdown(f"ğŸ”„ ç ”ç©¶è¿›è¡Œä¸­... ({int(elapsed)}ç§’)")
                        time.sleep(2)

                    if future.done():
                        result = future.result()
                        final_report, metadata = format_research_result(
                            result, user_input
                        )
                    else:
                        # è¶…æ—¶å¤„ç†
                        final_report = f"â° ç ”ç©¶è¶…æ—¶ã€‚ä¸»é¢˜: {user_input}\n\nç ”ç©¶è¿‡ç¨‹å¯èƒ½éœ€è¦æ›´é•¿æ—¶é—´ï¼Œè¯·ç¨åé‡è¯•ã€‚"
                        metadata = {"error": "timeout", "topic": user_input}
                else:
                    # æ¨¡æ‹Ÿæ¨¡å¼
                    final_report = f"""# {user_input} - æ·±åº¦ç ”ç©¶æŠ¥å‘Š (æ¨¡æ‹Ÿæ¨¡å¼)

## ğŸ“‹ æ‰§è¡Œæ‘˜è¦
åŸºäºæ‚¨æä¾›çš„ç ”ç©¶ä¸»é¢˜"{user_input}"ï¼Œæˆ‘ä»¬è¿›è¡Œäº†æ¨¡æ‹Ÿçš„æ·±åº¦åˆ†æã€‚

âš ï¸ **æ³¨æ„**: å½“å‰è¿è¡Œåœ¨æ¨¡æ‹Ÿæ¨¡å¼ä¸‹ï¼Œå› ä¸ºæ·±åº¦ç ”ç©¶æ¨¡å—æœªæ­£ç¡®åŠ è½½ã€‚

## ğŸ” æ ¸å¿ƒå‘ç°
1. **ä¸»è¦è¶‹åŠ¿**: è¯¥é¢†åŸŸæ­£åœ¨ç»å†å¿«é€Ÿå‘å±•
2. **å…³é”®æŒ‘æˆ˜**: å­˜åœ¨å¤šä¸ªæŠ€æœ¯å’Œå¸‚åœºæŒ‘æˆ˜  
3. **æœºé‡åˆ†æ**: è¯†åˆ«å‡ºé‡è¦çš„å‘å±•æœºé‡

## ğŸ“Š è¯¦ç»†åˆ†æ
### æŠ€æœ¯å±‚é¢
- æŠ€æœ¯åˆ›æ–°æŒç»­æ¨è¿›
- åŸºç¡€è®¾æ–½ä¸æ–­å®Œå–„
- æ ‡å‡†åŒ–è¿›ç¨‹åŠ é€Ÿ

### å¸‚åœºå±‚é¢
- å¸‚åœºæ¥å—åº¦é€æ­¥æå‡
- ç›‘ç®¡ç¯å¢ƒæ—¥è¶‹æ˜ç¡®
- æŠ•èµ„æ´»åŠ¨ä¿æŒæ´»è·ƒ

## ğŸ¯ ç»“è®ºä¸å»ºè®®
åŸºäºä»¥ä¸Šåˆ†æï¼Œæˆ‘ä»¬å»ºè®®ï¼š
1. å…³æ³¨æŠ€æœ¯å‘å±•åŠ¨æ€
2. è·Ÿè¸ªç›‘ç®¡æ”¿ç­–å˜åŒ–
3. æŠŠæ¡å¸‚åœºæœºé‡çª—å£

*æœ¬æŠ¥å‘ŠåŸºäºæ¨¡æ‹Ÿæ•°æ®ç”Ÿæˆï¼Œä»…ç”¨äºæ¼”ç¤ºç›®çš„ã€‚*"""
                    metadata = {
                        "sections": ["æ‰§è¡Œæ‘˜è¦", "æ ¸å¿ƒå‘ç°", "è¯¦ç»†åˆ†æ", "ç»“è®ºä¸å»ºè®®"],
                        "search_queries": ["æ¨¡æ‹ŸæŸ¥è¯¢1", "æ¨¡æ‹ŸæŸ¥è¯¢2", "æ¨¡æ‹ŸæŸ¥è¯¢3"],
                        "mode": "simulation",
                    }

                # æ¸…é™¤è¿›åº¦æ˜¾ç¤º
                progress_bar.empty()
                status_text.empty()
                thinking_placeholder.empty()

                # æ˜¾ç¤ºç»“æœ
                st.markdown(final_report)

                # æ·»åŠ å…ƒæ•°æ®
                with st.expander("ğŸ“‹ ç ”ç©¶è¯¦æƒ…"):
                    col_meta1, col_meta2 = st.columns(2)
                    with col_meta1:
                        st.write("**ç ”ç©¶ä¿¡æ¯:**")
                        st.write(f"â€¢ ä¸»é¢˜: {metadata.get('topic', user_input)}")
                        st.write(
                            f"â€¢ æ—¶é—´: {metadata.get('timestamp', time.strftime('%Y-%m-%d %H:%M:%S'))}"
                        )
                        if "sections_count" in metadata:
                            st.write(f"â€¢ ç« èŠ‚æ•°: {metadata['sections_count']}")
                        if "word_count" in metadata:
                            st.write(f"â€¢ å­—æ•°: {metadata['word_count']}")
                        if "mode" in metadata:
                            st.write(f"â€¢ æ¨¡å¼: {metadata['mode']}")

                    with col_meta2:
                        st.write("**æŠ€æœ¯è¯¦æƒ…:**")
                        if "sections" in metadata:
                            st.write("**ç ”ç©¶ç« èŠ‚:**")
                            for section in metadata["sections"]:
                                st.write(f"â€¢ {section}")
                        if "search_queries" in metadata:
                            st.write("**æœç´¢å…³é”®è¯:**")
                            for query in metadata["search_queries"]:
                                st.write(f"â€¢ {query}")
                        if "sources_used" in metadata:
                            st.write("â€¢ ä½¿ç”¨äº†å¤–éƒ¨æ•°æ®æº")

                # ä¿å­˜åˆ°æ¶ˆæ¯å†å²
                st.session_state.messages.append(
                    {"role": "assistant", "content": final_report, "metadata": metadata}
                )

                # æ›´æ–°çŠ¶æ€
                st.session_state.current_status = "ç ”ç©¶å®Œæˆ"

            except Exception as e:
                st.error(f"âŒ ç ”ç©¶è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
                st.session_state.current_status = f"é”™è¯¯: {str(e)}"

    # æ¸…ç©ºè¾“å…¥æ¡†
    st.session_state.topic_input = ""
    st.rerun()

# é¡µè„š
st.markdown("---")
st.markdown(
    """
    <div style="text-align: center; color: #666; padding: 1rem;">
        ğŸ”¬ Deep Research Assistant | Powered by LangGraph & Streamlit
    </div>
    """,
    unsafe_allow_html=True,
)

# å®æ—¶çŠ¶æ€æ›´æ–°ï¼ˆå¯é€‰ï¼‰
if st.session_state.current_status != "ç­‰å¾…è¾“å…¥":
    time.sleep(0.1)  # é¿å…è¿‡äºé¢‘ç¹çš„é‡æ–°è¿è¡Œ
